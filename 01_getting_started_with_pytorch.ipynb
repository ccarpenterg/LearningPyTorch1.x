{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_getting_started_with_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningPyTorch1.x/blob/master/01_getting_started_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsDBlN9rzm0E",
        "colab_type": "text"
      },
      "source": [
        "## Getting Started with PyTorch: Training a NN on MNIST\n",
        "\n",
        "This a small series of notebooks in which I introduce PyTorch, Facebook's machine learning framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZTfbDBH0XQ-",
        "colab_type": "text"
      },
      "source": [
        "Let's start by importing torch, which is the main library, torchvision and numpy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEMdXm--R0XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RK6E55_1ALO",
        "colab_type": "text"
      },
      "source": [
        "Pytorch is included by default in the Colab notebooks, but it's a good idea to check the installed version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crqFErSxekd7",
        "colab_type": "code",
        "outputId": "36e5ebd1-655c-469b-ddef-3101abf790c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('PyTorch version:', torch.__version__)\n",
        "print('Torchvision version:', torchvision.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.1.0\n",
            "Torchvision version: 0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcLTpCU2jSVq",
        "colab_type": "text"
      },
      "source": [
        "### Simple Neural Network\n",
        "\n",
        "We will start with the basic example of a shallow NN: an input layer, a hidden layer and the output layer. We'll use dropout to avoid overfitting.\n",
        "\n",
        "Each MNIST training example consists of a 28x28 pixels image in grayscale (1 channel), that is turned into a 784-elements vector. The input layer has 784 neurons, and we have a hidden layer of 128 neurons. The output layer has 1 neuron for each one of the classes, in this case 10 neurons (10 digits - 0, 1 2, 3, etc).\n",
        "\n",
        "To implement our neural network, we create the class BasicNN and inherit the methods and properties from the Module class (nn.Module):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM-ForR-l6jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(BasicNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAw-H2RWAIAF",
        "colab_type": "text"
      },
      "source": [
        "We'll be using the GPU that is included in the Colab notebooks, so we create a pytorch device and send the model to the device:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRlAtGqH7IFx",
        "colab_type": "code",
        "outputId": "a81e193a-bb20-48d9-8882-2beb69bc7cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "cuda = torch.device('cuda')\n",
        "\n",
        "model = BasicNN(28*28, 128, 10)\n",
        "model.to(cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BasicNN(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (drop): Dropout(p=0.2)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6tKMYL56u-f",
        "colab_type": "text"
      },
      "source": [
        "### MNIST\n",
        "\n",
        "The MNIST dataset is included in the torchvision module and it's really strighforward to download it. Before using MNIST we need to define a couple of transformations, which are map functions that are run through the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDj5nPWK7BjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.1307], [0.3081])\n",
        "])\n",
        "\n",
        "valid_transform = train_transform\n",
        "\n",
        "train_set = MNIST('./data/mnist', train=True, download=True, transform=train_transform)\n",
        "valid_set = MNIST('./data/mnist', train=False, download=True, transform=train_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njadg57rBsZH",
        "colab_type": "text"
      },
      "source": [
        "Now let's take a look at the shape of our datasets; as you can see we have a training set with 60,000 images (28x28) and a validation/test set with 10,000 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvs5FGUw4rpd",
        "colab_type": "code",
        "outputId": "4cf9e4fd-0798-4ade-de8c-813434947c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_set.data.shape)\n",
        "print(valid_set.data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9e1v9mx6pgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=128, num_workers=0, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=512, num_workers=0, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGLJonyAGDb2",
        "colab_type": "text"
      },
      "source": [
        "Now we create a 2D tensor of 28x28 with random elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlTAX7xpBEYE",
        "colab_type": "code",
        "outputId": "1da68cb5-a674-48f2-dbac-dd6cabc12ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input = torch.randn(28, 28, device=cuda)\n",
        "out = model(input)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0937,  0.0391,  0.2080,  0.1556,  0.2331, -0.5514, -0.0130,  0.2527,\n",
            "         0.3373, -0.1048], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6H9ouTpaprI",
        "colab_type": "code",
        "outputId": "44202f0d-014a-45d6-ecad-4cb853a3930d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X = torch.randn(28, 28) # matrix\n",
        "print(X.shape)\n",
        "\n",
        "x = torch.flatten(X) # vector\n",
        "print(x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([28, 28])\n",
            "torch.Size([784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it8hiwlF1IBA",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_ek-1aKVgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/docs/stable/optim.html#torch.optim.SGD\n",
        "# Stochastic gradient descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpi2WywW1OcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(model, loss_fn, optimizer):\n",
        "    \n",
        "    # https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train\n",
        "    # set the module in training mode\n",
        "    model.train()\n",
        "    \n",
        "    train_batch_losses = []\n",
        "    \n",
        "    for batch, labels in train_loader:\n",
        "        \n",
        "        #send the training data to the GPU\n",
        "        batch = batch.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #set all gradient to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #forward propagation\n",
        "        y_pred = model(batch)\n",
        "        \n",
        "        #calculate loss\n",
        "        loss = loss_fn(y_pred, labels)\n",
        "        \n",
        "        #backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        #update the parameters (weights and biases)\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_batch_losses.append(loss)\n",
        "        \n",
        "        mean_loss = statistics.mean(train_batch_losses)\n",
        "    \n",
        "    return mean_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCYCnM4aPoE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, loss_fn, optimizer):\n",
        "    \n",
        "    # set the model in validation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # save predictions for later\n",
        "    predictions = []\n",
        "    \n",
        "    # stop tracking the parameters for backpropagation\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        validation_batch_losses = []\n",
        "        \n",
        "        for batch, labels in valid_loader:\n",
        "            \n",
        "            # send the validation data to the GPU\n",
        "            batch = batch.to(cuda)\n",
        "            labels = labels.to(cuda)\n",
        "            \n",
        "            # forward propagation\n",
        "            labels_pred = model(batch)\n",
        "            \n",
        "            # calculate the loss\n",
        "            loss = loss_fn(labels_pred, labels)\n",
        "            \n",
        "            validation_train_losses.append(loss)\n",
        "            \n",
        "            mean_loss = statistics.mean(validation_batch_loss)\n",
        "    \n",
        "    return mean_loss\n",
        "            \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcxTN-cPzHY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(1, 1+10):\n",
        "    \n",
        "    print('Epoch number ', epoch)\n",
        "    \n",
        "    train_loss = train(model, loss_fn, optimizer)\n",
        "    \n",
        "    print('Training loss:', train_loss)\n",
        "    \n",
        "    valid_loss = validate(model, loss_fn, optimizer)\n",
        "    \n",
        "    print('Validation loss:', valid_loss)\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}